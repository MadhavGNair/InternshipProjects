{"page_content": "8 \n \n [Public]  \nresearch and other critical \nneeds.    approximately 27.8 \nmillion.  \n \nDive rsity,\u202fBelonging \nand\u202fInclusion : \nWe encourage and support \ncreative minds from diverse \nbackgrounds to work together \nin an engaging and open \nenvironment.   \n  2) 70%  of our employees to participate \nin\u202fAMD employee resource groups \nand/or other AMD inclusion initiatives by \n2025.2  2) ON TRACK : In 2021, 52 \npercent of AMD employees \ncontributed to activities \nunder this goal due to an \nincrease in ERG \nmembership, employee \nvolunteers and charitable \ndonors.  \n \nEnvironmental Sustainability : \nWe are steadfast in our \ncommitment to sustainability \nby sourcing renewable energy, \nengaging our employees and \nsuppliers on environmenta l \ninitiatives, and helping end -3) 30x increase in energy efficiency for \nAMD processors and accelerators \npowering servers for artificial \nintelligence -training and high -\nperformance computing by 2025 (base \nyear 2020).3 \n 3) ON TRACK : In 2021, \nAMD achieved a 3.9x \nincrease, and midway \nthrough 2022  \nreached a 6.8x \nimprovement in energy  \nefficiency compared to \n2020.5 \n \n2 These are voluntary initiatives in which an employee chooses to actively participate in one or more employee engagement \nprograms that foster a culture of belonging, psychological safety and meaningful connection to AMD.  \n3 Includes AMD high -performance CPU and GPU accelerators used for AI training and high -performance computing in a 4 -\nAccelerator, CPU -hosted configuration. Goal calculations are based on performance scores as measured by standard \nperformance metrics (HPC: Linpack DGEMM kernel FLOPS with 4k matrix size. AI training: lower precision training -focused \nfloating -point math GEMM kernels such as FP 16 or BF16 FLOPS operating on 4k matrices) divided by the rated power \nconsumption of a representative accelerated compute node, including the CPU host + memory, and 4 GPU accelerators.  \n5 EPYC -030: AMD takes compute node performance/Watt measurements for AMD high performance CPU and GPU accelerators \nused for AI training and High -Performance Computing in a 4-Accelerator, CPU -hosted configuration.   \n\u2022 Performance for HPC workloads is based on Linpack DGEMM kernel FLOPS with 4k matrix size. Performance for AI \ntraining is based on lower precision training -focused floating -point math GEMM kernels such as FP16 or BF 16 FLOPS \noperating on 4k matrices.   \n\u2022 Watts are based on the TDP of a representative accelerated compute node including the CPU host + memory, and 4 \nGPU accelerators   \n \nTo make the goal particularly relevant to worldwide energy use, AMD worked with Koomey Ana lytics to assess available \nresearch and data that includes segment -specific datacenter power utilization effectiveness (PUE) including GPU HPC and \nmachine learning (ML) installations. The AMD CPU socket and GPU node power consumptions incorporate segment -specific \nutilization (active vs. idle) percentages and are multiplied by PUE to determine actual total energy use for calculation of t he \nperformance per Watt.   \nThe energy consumption baseline uses the same industry energy per operation improvement rates as were observed from \n2015 -2020, with this rate of change extrapolated to 2025. The AMD goal trend line (Table 1) shows the exponential \nimprovements needed to hit the goal of thirtyfold efficiency improvements by 2025. The actual AMD products released (Table \n2) are the source of the efficiency improvements shown for AMD goal status in Table 1.   \n ", "metadata": {"source": "NASDAQ_AMD_2022.pdf", "page": 7, "parser": "pypdf", "split_method": "page", "run_time": "2024-05-29 08:35:04"}, "type": "Document"}